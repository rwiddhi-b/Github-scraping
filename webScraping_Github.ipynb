{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMsiGyMKw/5MROmeQoEMii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rwiddhi-b/Github-scraping/blob/main/webScraping_Github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping Top Repositories for Topics on GitHub\n",
        "Tools used (Python, requests, Beautiful Soup, Pandas)\n",
        "\n"
      ],
      "metadata": {
        "id": "XQvn0YIoChpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps we'll follow:\n",
        "\n",
        "We're going to scrape https://github.com/topics\n",
        "\n",
        "We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
        "\n",
        "For each topic, we'll get the top 25 repositories in the topic from the topic page\n",
        "\n",
        "For each repository, we'll grab the repo name, username, stars and repo URL\n",
        "\n",
        "For each topic we'll create a CSV file."
      ],
      "metadata": {
        "id": "X6IJFof5Cx9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrape the list of topics from Github\n",
        "Steps:\n",
        "\n",
        "use requests to downlaod the page\n",
        "\n",
        "use BS4 to parse and extract information\n",
        "\n",
        "convert to a Pandas dataframe"
      ],
      "metadata": {
        "id": "v1-Ns3rXC4VU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27BJo7a8CZcl"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_topics_page():\n",
        "  topic_url = 'https://github.com/topics'\n",
        "  # Download page \n",
        "  response = requests.get(topic_url)\n",
        "  # check successful status\n",
        "  if response.status_code != 200:\n",
        "    raise Exception('Failed to load page {}'.format(topic_url))\n",
        "  # parse using beautiful soup\n",
        "  topic_doc = BeautifulSoup (response.text, 'html.parser')\n",
        "  return topic_doc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_doc = get_topics_page()"
      ],
      "metadata": {
        "id": "CVdnxrtiD5Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(topic_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mr0sNYWEbcp",
        "outputId": "e4991dcc-73bb-48b4-e48c-afb7b9cbe5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bs4.BeautifulSoup"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps to parse information from the page"
      ],
      "metadata": {
        "id": "Xf7wflTkE-RH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`get_topic_titles` can be used to get the list of titles"
      ],
      "metadata": {
        "id": "cs8p6QpEFmpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_titles (topic_doc):\n",
        "  selection_class ='f3 lh-condensed mb-0 mt-1 Link--primary'\n",
        "  topic_title_tags = topic_doc.find_all('p', {'class': selection_class})\n",
        "  topic_titles = []\n",
        "  for tag in topic_title_tags: \n",
        "    topic_titles.append(tag.text)\n",
        "  return topic_titles"
      ],
      "metadata": {
        "id": "EGnP9Cf7EeF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = get_topic_titles(topic_doc)\n",
        "len(titles) #30\n",
        "titles[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PxdOzkhFyaR",
        "outputId": "c29678d0-f2d1-49ed-c9bb-2f6bdff5fc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly we have defined functions for descriptions and URLs."
      ],
      "metadata": {
        "id": "k7ATv1AbG_MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_descs(topic_doc):\n",
        "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
        "    topic_desc_tags = topic_doc.find_all('p', {'class': desc_selector})\n",
        "    topic_descs = []\n",
        "    for tag in topic_desc_tags:\n",
        "        topic_descs.append(tag.text.strip())\n",
        "    return topic_descs"
      ],
      "metadata": {
        "id": "irztmesWF5Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc = get_topic_descs(topic_doc)\n",
        "len(desc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RXVfl_2HXQl",
        "outputId": "3dcdde78-2e76-440a-94d0-ef2c123f4944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_urls(topic_doc):\n",
        "    topic_link_tags = topic_doc.find_all('a', {'class': 'no-underline flex-1 d-flex flex-column'})\n",
        "    topic_urls = []\n",
        "    base_url = 'https://github.com'\n",
        "    for tag in topic_link_tags:\n",
        "        topic_urls.append(base_url + tag['href'])\n",
        "    return topic_urls"
      ],
      "metadata": {
        "id": "yEPEImReHOhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = get_topic_urls(topic_doc)\n",
        "len(urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6dhZYAWHUdz",
        "outputId": "855c3223-6c64-4460-f688-518177055604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0XVjKQZZIc4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_topics():\n",
        "    topics_url = 'https://github.com/topics'\n",
        "    response = requests.get(topics_url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception('Failed to load page {}'.format(topics_url))\n",
        "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    topics_dict = {\n",
        "        'title': get_topic_titles(topic_doc),\n",
        "        'description': get_topic_descs(topic_doc),\n",
        "        'url': get_topic_urls(topic_doc)\n",
        "    }\n",
        "    return pd.DataFrame(topics_dict)"
      ],
      "metadata": {
        "id": "_2v3CdvjIEd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the top 25 repositories from a topic page"
      ],
      "metadata": {
        "id": "mm6xGjZVU2ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_page(topic_url):\n",
        "    # Download the page\n",
        "    response = requests.get(topic_url)\n",
        "    # Check successful response\n",
        "    if response.status_code != 200:\n",
        "        raise Exception('Failed to load page {}'.format(topic_url))\n",
        "    # Parse using Beautiful soup\n",
        "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
        "    return topic_doc"
      ],
      "metadata": {
        "id": "vhSSJaktU2FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = get_topic_page('https://github.com/topics/3d')"
      ],
      "metadata": {
        "id": "RddxXVgXVkTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_star_count(stars):\n",
        "    stars=stars.strip()\n",
        "    if stars[-1]=='k':\n",
        "        return int(float(stars[:-1])*1000)\n",
        "    return(int(stars))"
      ],
      "metadata": {
        "id": "ILY9O01tVlQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_repo_info(h1_tag, star_tag):\n",
        "    # returns all the required info about a repository\n",
        "    a_tags = h1_tag.find_all('a')\n",
        "    base_url = 'https://github.com'\n",
        "    username = a_tags[0].text.strip()\n",
        "    repo_name = a_tags[1].text.strip()\n",
        "    repo_url =  base_url + a_tags[1]['href']\n",
        "    stars = parse_star_count(star_tag.text.strip())\n",
        "    return username, repo_name, stars, repo_url"
      ],
      "metadata": {
        "id": "zOROHylaVvJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topic_repos(topic_doc):\n",
        "    # Get the h1 tags containing repo title, repo URL and username\n",
        "    repo_tags = topic_doc.find_all('article',{'class':'border rounded color-shadow-small color-bg-subtle my-4'})\n",
        "\n",
        "    # Get star tags\n",
        "    star_tags=topic_doc.find_all('span',{'id':'repo-stars-counter-star'})\n",
        "    \n",
        "    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n",
        "\n",
        "    # Get repo info\n",
        "    for i in range(len(repo_tags)):\n",
        "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
        "        topic_repos_dict['username'].append(repo_info[0])\n",
        "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
        "        topic_repos_dict['stars'].append(repo_info[2])\n",
        "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
        "        \n",
        "    return pd.DataFrame(topic_repos_dict)"
      ],
      "metadata": {
        "id": "HMEIDl9TV26r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def scrape_topic(topic_url, path):\n",
        "    if os.path.exists(path):\n",
        "        print(\"The file {} already exists. Skipping...\".format(path))\n",
        "        return\n",
        "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
        "    topic_df.to_csv(path, index=None)"
      ],
      "metadata": {
        "id": "2D5XpgrCWJ6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting it all together\n",
        "We have a function to get the list of topics\n",
        "\n",
        "We have a function to create a CSV file for scraped repos from a topics page\n",
        "\n",
        "We now create a function to put them together"
      ],
      "metadata": {
        "id": "K1AeRHDkWySD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_topics_repos():\n",
        "    print('Scraping list of topics')\n",
        "    topics_df = scrape_topics()\n",
        "    \n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    \n",
        "    for index, row in topics_df.iterrows():\n",
        "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
        "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
      ],
      "metadata": {
        "id": "_7Q2B95DWRSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We run it to scrape the top repos for the all the topics on the first page of https://github.com/topics"
      ],
      "metadata": {
        "id": "nTPhetv6Xd3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scrape_topics_repos()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS-372L8W_n9",
        "outputId": "60b5b751-3c7b-4323-b3ff-aa393c2d53b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping list of topics\n",
            "Scraping top repositories for \"3D\"\n",
            "Scraping top repositories for \"Ajax\"\n",
            "Scraping top repositories for \"Algorithm\"\n",
            "Scraping top repositories for \"Amp\"\n",
            "Scraping top repositories for \"Android\"\n",
            "Scraping top repositories for \"Angular\"\n",
            "Scraping top repositories for \"Ansible\"\n",
            "Scraping top repositories for \"API\"\n",
            "Scraping top repositories for \"Arduino\"\n",
            "Scraping top repositories for \"ASP.NET\"\n",
            "Scraping top repositories for \"Atom\"\n",
            "Scraping top repositories for \"Awesome Lists\"\n",
            "Scraping top repositories for \"Amazon Web Services\"\n",
            "Scraping top repositories for \"Azure\"\n",
            "Scraping top repositories for \"Babel\"\n",
            "Scraping top repositories for \"Bash\"\n",
            "Scraping top repositories for \"Bitcoin\"\n",
            "Scraping top repositories for \"Bootstrap\"\n",
            "Scraping top repositories for \"Bot\"\n",
            "Scraping top repositories for \"C\"\n",
            "Scraping top repositories for \"Chrome\"\n",
            "Scraping top repositories for \"Chrome extension\"\n",
            "Scraping top repositories for \"Command line interface\"\n",
            "Scraping top repositories for \"Clojure\"\n",
            "Scraping top repositories for \"Code quality\"\n",
            "Scraping top repositories for \"Code review\"\n",
            "Scraping top repositories for \"Compiler\"\n",
            "Scraping top repositories for \"Continuous integration\"\n",
            "Scraping top repositories for \"COVID-19\"\n",
            "Scraping top repositories for \"C++\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqJr0l9EXVaR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}